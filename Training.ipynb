{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VncebmJOLooS","colab_type":"text"},"source":["# training"]},{"cell_type":"markdown","metadata":{"id":"65qtem6CLyvL","colab_type":"text"},"source":["## imports"]},{"cell_type":"code","metadata":{"id":"vLjWvt_aL0sS","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import keras\n","from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, UpSampling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense, MaxPool2D\n","from keras.models import Sequential, load_model\n","from keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array, image\n","from keras.callbacks import ModelCheckpoint\n","# from keras.callbacks import *\n","from keras.utils import plot_model\n","from keras import backend as kb\n","\n","import numpy as np\n","import glob\n","import cv2\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uHoFfzlyO95u","colab_type":"text"},"source":["## configs"]},{"cell_type":"code","metadata":{"id":"bdOzgdVQO_OV","colab_type":"code","colab":{}},"source":["checkpoint_path = \".../variables/checkpoints\"\n","chunks_path = \".../variables/dataset/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99r6NMoBLqcx","colab_type":"text"},"source":["## data preparation"]},{"cell_type":"code","metadata":{"id":"ib_FbOQZLbgD","colab_type":"code","colab":{}},"source":["# load batches paths (X, y)\n","X_paths = []\n","y_paths = []\n","\n","for i, filename in enumerate(glob.glob(chunks_path+'X*.pickle')):\n","  X_paths.append(filename)\n","\n","for i, filename in enumerate(glob.glob(chunks_path+'y*.pickle')):\n","  y_paths.append(filename)\n","\n","train_batches = len(X_paths)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxhnJk4uN5Pr","colab_type":"code","colab":{}},"source":["# connect all batches\n","X = []\n","y = []\n","\n","for i in range(0, len(X_paths)):\n","  print(\"---- \"+str(i)+\"/\"+str(len(X_paths))+\" ----\")\n","\n","  with open(X_paths[i], 'rb') as f:\n","    X_l = pickle.load(f)\n","  with open(y_paths[i], 'rb') as f:\n","    y_l = pickle.load(f)\n","\n","  X_l = X_l.astype('float16')\n","  y_l = y_l.astype('float16')\n","\n","  if i == 0:\n","    X = X_l\n","    y = y_l\n","  else:\n","    X = np.concatenate((X,X_l))\n","    y = np.concatenate((y,y_l))\n","\n","  del X_l\n","  del y_l\n","\n","print(X.shape)\n","print(y.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZ8ajq-7Ls62","colab_type":"text"},"source":["## model"]},{"cell_type":"code","metadata":{"id":"a_4xoI0vLuv3","colab_type":"code","colab":{}},"source":["# define custom losses - euclidean, cross_entropy loss\n","def euclidean_loss(y_true, y_pred):\n","  return kb.sqrt( kb.sum( kb.square(y_true - y_pred ), axis=-1 ))\n","\n","def cross_entorpy_loss(y_true, y_pred):\n","  return -1.0 * kb.sum(y_true*kb.log(y_pred), axis=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhNrws78Oo_2","colab_type":"code","colab":{}},"source":["# define model, and construct the network\n","\n","model = Sequential()\n","\n","# conv 1\n","model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=(SIZE,SIZE,1)))\n","model.add(Conv2D(64,(3,3),padding=\"same\", strides=2))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 2\n","model.add(Conv2D(128, (3,3), padding=\"same\"))\n","model.add(Conv2D(128,(3,3),padding=\"same\", strides=2))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 3\n","model.add(Conv2D(256, (3,3), padding=\"same\"))\n","model.add(Conv2D(256, (3,3), padding=\"same\"))\n","model.add(Conv2D(256,(3,3),padding=\"same\", strides=2))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 4\n","model.add(Conv2D(512, (3,3), padding=\"same\"))\n","model.add(Conv2D(512, (3,3), padding=\"same\"))\n","model.add(Conv2D(512, (3,3), padding=\"same\"))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 5 \n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","#conv 6\n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(keras.layers.ZeroPadding2D(padding=(2, 2)))\n","model.add(Conv2D(512, (3,3), dilation_rate=2, padding=\"valid\"))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 7\n","model.add(Conv2D(512, (3,3), padding=\"same\", dilation_rate=1))\n","model.add(Conv2D(512, (3,3), padding=\"same\", dilation_rate=1))\n","model.add(Conv2D(512, (3,3), padding=\"same\", dilation_rate=1))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","\n","# conv 8\n","# deconv\n","model.add(Conv2DTranspose(256, (4,4), padding=\"same\", dilation_rate=1, strides=2))\n","model.add(Conv2D(256, (4,4), padding=\"same\", dilation_rate=1))\n","model.add(Conv2D(256, (4,4), padding=\"same\", dilation_rate=1))\n","\n","# softmax\n","model.add(Conv2D(313, (1,1), padding=\"same\", dilation_rate=1))\n","model.add(BatchNormalization())\n","model.add(Activation('softmax'))\n","\n","# decoding\n","model.add(Conv2D(2, (1,1), padding=\"same\", dilation_rate=1))\n","\n","model.add(UpSampling2D((4,4)))\n","\n","\n","model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n","# model.compile(optimizer='adam', loss=euclidean_loss, metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6Gro3inLvGG","colab_type":"text"},"source":["## train"]},{"cell_type":"code","metadata":{"id":"SpeabWKYLx2R","colab_type":"code","colab":{}},"source":["# store checkpoints, so when training stops for some reason, we have backup files, and train the model\n","checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n","callbacks_list = [checkpoint]\n","\n","model.fit(X,y,epochs=100, validation_split=0.1, batch_size=50, callbacks=callbacks_list, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z0U9qaswPGSm","colab_type":"code","colab":{}},"source":["# save model in .model format\n","model.save(\".../models/image_colorization.model\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"91RCwc3jPshK","colab_type":"code","colab":{}},"source":["# in case of training stoping use the following cells\n","filepath = \".../variables/checkpoints/last_checkpoint.hdf5\"\n","\n","model_cont = tf.keras.models.load_model(filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfZuyT8sQmpv","colab_type":"code","colab":{}},"source":["# continue training, with the desired epoches left\n","model_cont.fit(X,y,epochs=20, batch_size=50,  verbose=1)"],"execution_count":0,"outputs":[]}]}